#! /usr/bin/env python
# -*- coding: utf-8 -*-

from charon import deployment
from prettytable import PrettyTable
import argparse
import os
import re
import sys
import subprocess
import charon.parallel
import charon.util
import charon.import_json
import time
from pprint import pprint

home = os.environ.get("HOME", "") + "/.charon"
if not os.path.exists(home): os.makedirs(home, 0700)


def op_list_deployments():
    db = deployment.open_database(args.state_file)
    uuids = deployment.query_deployments(db)
    tbl = PrettyTable(["UUID", "Name", "Description", "# Machines", "Type"])
    for uuid in uuids:
        depl = deployment.open_deployment(db, uuid=uuid)
        tbl.add_row(
            [uuid, depl.name or "(none)",
             depl.description, len(depl.machines),
             ", ".join(set([m.get_type() for m in depl.machines.itervalues()]))
            ])
    print tbl


def open_deployment():
    db = deployment.open_database(args.state_file)
    depl = deployment.open_deployment(db, uuid=args.deployment)

    depl.extra_nix_path = sum(args.nix_path or [], [])
    for (n, v) in args.nix_options or []: depl.extra_nix_flags.extend(["--option", n, v])
    if args.max_jobs != None: depl.extra_nix_flags.extend(["--max-jobs", str(args.max_jobs)])
    if args.max_jobs != None: depl.extra_nix_flags.extend(["--max-jobs", str(args.max_jobs)])
    if args.keep_going: depl.extra_nix_flags.append("--keep-going")
    if args.keep_failed: depl.extra_nix_flags.append("--keep-failed")

    return depl


def set_name(depl, name):
    if not name: return
    if not re.match("^[a-zA-Z_\-][a-zA-Z0-9_\-\.]*$", name):
        raise Exception("invalid deployment name ‘{0}’".format(name))
    depl.name = name


def modify_deployment(depl):
    depl.nix_exprs = [os.path.abspath(x) if x[0:1] != '<' else x for x in args.nix_exprs]
    depl.nix_path = [charon.util.abs_nix_path(x) for x in sum(args.nix_path or [], [])]
    set_name(depl, args.name)


def op_create():
    db = deployment.open_database(args.state_file)
    depl = deployment.create_deployment(db)
    sys.stderr.write("created deployment ‘{0}’\n".format(depl.uuid))
    modify_deployment(depl)
    sys.stdout.write(depl.uuid + "\n")


def op_modify():
    depl = open_deployment()
    modify_deployment(depl)


def op_clone():
    depl = open_deployment()
    depl2 = depl.clone()
    sys.stderr.write("created deployment ‘{0}’\n".format(depl2.uuid))
    set_name(depl2, args.name)
    sys.stdout.write(depl2.uuid + "\n")


def op_delete():
    depl = open_deployment()
    depl.delete()


def op_import_json():
    depl = charon.import_json.import_json(args.state_file, args.json_file)
    set_name(depl, args.name)


def op_info():
    table_header = ["Name", "Status", "Type", "Resource Id", "IP address"]

    def state(depl, d, m):
        if not d and (depl.definitions != None or m.obsolete): return "Obsolete"
        if d and m and m.obsolete: return "Revived"
        if not m: return "New"
        if deployment.is_machine(m) and depl.configs_path != m.cur_configs_path: return "Outdated"
        return "Up-to-date"

    def do_eval(depl):
        if not args.no_eval:
            try:
                depl.evaluate()
            except charon.deployment.NixEvalError:
                sys.stderr.write(charon.util.ansi_warn("warning: evaluation of the deployment specification failed; status info may be incorrect\n\n"))
                depl.definitions = None

    def print_deployment(depl):
        definitions = depl.definitions or {}

        # Sort machines by type, then name.  Sort numbers in machine
        # names numerically (e.g. "foo10" comes after "foo9").
        def name_to_key(name):
            xs = [int(x) if x.isdigit() else x for x in re.split('(\d+)', name)]
            print xs
            d = definitions.get(name)
            r = depl.resources.get(name)
            return [r.get_type(), xs] if r else [d.get_type(), xs]
        names = sorted(
            set(definitions.keys()) | set(depl.resources.keys()), 
            key=name_to_key
            )

        for name in names:
            d = definitions.get(name)
            r = depl.resources.get(name)
            if args.plain:
                print "\t".join(
                    ([depl.uuid] if args.all else []) +
                    [name,
                     state(depl, d, r).lower(),
                     r.show_type() if r else d.show_type(),
                     r.vm_id or "" if r and deployment.is_machine(r) else "",
                     r.public_ipv4 or "" if r and deployment.is_machine(r) else "",
                     r.private_ipv4 or "" if r and deployment.is_machine(r) else ""
                    ])
            else:
                tbl.add_row(
                    ([depl.name or depl.uuid] if args.all else []) +
                    [name,
                     "{0} / {1}".format(r.show_state() if r else "Missing", state(depl, d, r)),
                     r.show_type() if r else d.show_type(),
                     r.resource_id or "" if r else "",
                     r.public_ipv4 or r.private_ipv4 or "" if r and deployment.is_machine(r)  else ""
                    ])

    if args.all:
        db = deployment.open_database(args.state_file)
        uuids = deployment.query_deployments(db)
        if not args.plain: tbl = PrettyTable(["Deployment"] + table_header)
        for uuid in uuids:
            depl = deployment.open_deployment(db, uuid=uuid)
            do_eval(depl)
            print_deployment(depl)
        if not args.plain: print tbl

    else:
        depl = open_deployment()
        do_eval(depl)

        if args.plain:
            print_deployment(depl)
        else:
            print "Network name:", depl.name or "(none)"
            print "Network UUID:", depl.uuid
            print "Network description:", depl.description
            print "Nix expressions:", ", ".join(depl.nix_exprs)
            if depl.nix_path != []: print "Nix path:", ", ".join(depl.nix_path)
            if depl.rollback_enabled: print "Nix profile:", depl.get_profile()
            if depl.args != {}: print "Nix arguments:", ", ".join([n + " = " + v for n, v in depl.args.iteritems()])
            print
            tbl = PrettyTable(table_header)
            print_deployment(depl)
            print tbl


def op_check():
    def check(depl):
        for m in depl.active.itervalues():
            m.check()
    if args.all:
        db = deployment.open_database(args.state_file)
        uuids = deployment.query_deployments(db)
        for uuid in uuids:
            depl = deployment.open_deployment(db, uuid=uuid)
            sys.stderr.write("{0}:\n".format(depl.name or depl.uuid))
            check(depl)
    else:
       check(open_deployment())


def print_backups(depl, backups):
    print "Network UUID:", depl.uuid
    print "Network description:", depl.description
    tbl = PrettyTable(["Backup ID", "Status", "Info"])
    for k, v in sorted(backups.items(), reverse=True):
        fst = v['info'][0] if len(v['info']) > 0 else ""
        tbl.add_row([k,v['status'], fst])
        for i in v['info'][1:]:
            tbl.add_row(["", "", i])
    print tbl


def op_clean_backups():
    depl = open_deployment()
    depl.clean_backups(args.keep)


def op_remove_backup():
    depl = open_deployment()
    depl.remove_backup(args.backupid)


def op_backup():
    depl = open_deployment()
    backups = depl.get_backups(include=args.include or [], exclude=args.exclude or [])
    backups_status = [b['status'] for _, b in backups.items()]
    if "running" in backups_status and not args.force:
        raise Exception("There are still backups running, use --force to run a new backup concurrently (not advised!)")
    else:
        backup_id = depl.backup(include=args.include or [], exclude=args.exclude or [])
        print backup_id


def op_backup_status():
    depl = open_deployment()
    backupid = args.backupid
    while True:
        backups = depl.get_backups(include=args.include or [], exclude=args.exclude or [])

        if backupid or args.latest:
            sorted_backups = sorted(backups.keys(), reverse=True)
            if args.latest:
                if len(backups) == 0:
                    Exception("no backups found!")
                backupid = sorted_backups[0]

            _backups = {}
            _backups[backupid] = backups[backupid]
        else:
            _backups = backups

        print_backups(depl, _backups)

        backups_status = [b['status'] for _, b in _backups.items()]
        if "running" in backups_status:
            if args.wait:
                print "waiting for 30 seconds..."
                time.sleep(30)
            else:
                raise Exception("backup {0} not yet finished".format(backupid))
        else:
            return


def op_restore():
    depl = open_deployment()
    depl.restore(include=args.include or [], exclude=args.exclude or [], backup_id=args.backupid)


def op_deploy():
    depl = open_deployment()
    if args.confirm: depl.auto_response = "y"
    depl.deploy(dry_run=args.dry_run, build_only=args.build_only,
                create_only=args.create_only, copy_only=args.copy_only,
                include=args.include or [], exclude=args.exclude or [],
                check=args.check, kill_obsolete=args.kill_obsolete,
                allow_reboot=args.allow_reboot,
                max_concurrent_copy=args.max_concurrent_copy)


def op_send_keys():
    depl = open_deployment()
    depl.send_keys(include=args.include or [], exclude=args.exclude or [])


def op_set_args():
    depl = open_deployment()
    for [n, v] in args.args or []: depl.set_arg(n, v)
    for [n, v] in args.argstrs or []: depl.set_argstr(n, v)
    for [n] in args.unset or []: depl.unset_arg(n)


def op_destroy():
    depl = open_deployment()
    if args.confirm: depl.auto_response = "y"
    depl.destroy_resources(include=args.include or [], exclude=args.exclude or [])


def op_reboot():
    depl = open_deployment()
    depl.reboot_machines(include=args.include or [], exclude=args.exclude or [], wait=args.wait)


def op_stop():
    depl = open_deployment()
    depl.stop_machines(include=args.include or [], exclude=args.exclude or [])


def op_start():
    depl = open_deployment()
    depl.start_machines(include=args.include or [], exclude=args.exclude or [])


def op_rename():
    depl = open_deployment()
    depl.rename(args.current_name, args.new_name)


def op_show_physical():
    depl = open_deployment()
    depl.evaluate()
    sys.stdout.write(depl.get_physical_spec())


def parse_machine(name):
    return ("root", name) if name.find("@") == -1 else name.split("@", 1)


def op_ssh():
    depl = open_deployment()
    (username, machine) = parse_machine(args.machine)
    m = depl.machines.get(machine)
    if not m: raise Exception("unknown machine ‘{0}’".format(machine))
    ssh_name = m.get_ssh_name()
    print >> sys.stderr, "connecting to {0}...".format(ssh_name)
    res = subprocess.call(["ssh", username + "@" + ssh_name] + m.get_ssh_flags() + args.args)
    sys.exit(res)


def op_ssh_for_each():
    depl = open_deployment()
    res2 = 0
    if args.parallel:
        def worker(m):
            return m._logged_exec(["ssh", "root@" + m.get_ssh_name()] + m.get_ssh_flags() + args.args, check=False)
        results = charon.parallel.run_tasks(nr_workers=len(depl.machines), tasks=depl.active.itervalues(), worker_fun=worker)
    else:
        results = []
        for m in depl.active.itervalues():
            ssh_name = m.get_ssh_name()
            print >> sys.stderr, "running command on ‘{0}’...".format(m.name)
            results.append(subprocess.call(["ssh", "root@" + ssh_name] + m.get_ssh_flags() + args.args))
    sys.exit(max(results) if results != [] else 0)


def scp_loc(ssh_name, remote, loc):
    return "root@{0}:{1}".format(ssh_name, loc) if remote else loc


def op_scp():
    depl = open_deployment()
    m = depl.machines.get(args.machine)
    if not m: raise Exception("unknown machine ‘{0}’".format(args.machine))
    ssh_name = m.get_ssh_name()
    from_loc = scp_loc(ssh_name, args.scp_from, args.source)
    to_loc = scp_loc(ssh_name, args.scp_to, args.destination)
    print >> sys.stderr, "scp {0} -> {1}".format(ssh_name, from_loc, to_loc)
    res = subprocess.call([ "scp", "-r"] + m.get_ssh_flags() + [from_loc, to_loc])
    sys.exit(res)


def op_show_option():
    depl = open_deployment()
    sys.stdout.write(depl.evaluate_option_value(args.machine, args.option, xml=args.xml))


def op_list_generations():
    depl = open_deployment()
    if not depl.rollback_enabled:
        raise Exception("rollback is not enabled for this network; please set ‘network.enableRollback’ to ‘true’ and redeploy")
    if subprocess.call(["nix-env", "-p", depl.get_profile(), "--list-generations"]) != 0:
        raise Exception("nix-env --list-generations failed")


def op_rollback():
    depl = open_deployment()
    depl.rollback(args.generation,
                  include=args.include or [], exclude=args.exclude or [],
                  check=args.check, allow_reboot=args.allow_reboot,
                  max_concurrent_copy=args.max_concurrent_copy)


# Set up the parser.
parser = argparse.ArgumentParser(description='NixOS cloud deployment tool', prog='charon')
parser.add_argument('--version', action='version', version='Charon 0.1')

subparsers = parser.add_subparsers(help='sub-command help')

def add_subparser(name, help):
    subparser = subparsers.add_parser(name, help=help)
    subparser.add_argument('--state', '-s', dest='state_file', metavar='FILE',
                           default=os.environ.get("CHARON_STATE", home + "/deployments.charon"),
                           help='path to state file')
    subparser.add_argument('--deployment', '-d', dest='deployment', metavar='UUID',
                           default=os.environ.get("CHARON_DEPLOYMENT", None), help='UUID of the deployment')
    subparser.add_argument('--debug', action='store_true', help='enable debug output')
    subparser.add_argument('--confirm', action='store_true', help='confirm dangerous operations; do not ask')

    # Nix options that we pass along.
    subparser.add_argument('-I', nargs=1, action="append", dest="nix_path", metavar='PATH', help='append a directory to the Nix search path')
    subparser.add_argument("--max-jobs", '-j', type=int, metavar='N', help='set maximum number of concurrent Nix builds')
    subparser.add_argument("--keep-going", action='store_true', help='keep going after failed builds')
    subparser.add_argument("--keep-failed", '-K', action='store_true', help='keep temporary directories of failed builds')
    subparser.add_argument('--option', nargs=2, action="append", dest="nix_options", metavar=('NAME', 'VALUE'), help='set a Nix option')

    return subparser

subparser = add_subparser('list', help='list all known deployments')
subparser.set_defaults(op=op_list_deployments)

def add_common_modify_options(subparser):
    subparser.add_argument('nix_exprs', nargs='+', metavar='NIX-FILE', help='Nix expression(s) defining the network')
    subparser.add_argument('--name', '-n', dest='name', metavar='NAME', help='symbolic name of deployment')

subparser = add_subparser('create', help='create a new deployment')
subparser.set_defaults(op=op_create)
add_common_modify_options(subparser)

subparser = add_subparser('modify', help='modify an existing deployment')
subparser.set_defaults(op=op_modify)
add_common_modify_options(subparser)

subparser = add_subparser('clone', help='clone an existing deployment')
subparser.set_defaults(op=op_clone)
subparser.add_argument('--name', '-n', dest='name', metavar='NAME', help='symbolic name of the cloned deployment')

subparser = add_subparser('delete', help='delete a deployment')
subparser.set_defaults(op=op_delete)

subparser = add_subparser('import-json', help='import a legacy JSON state file')
subparser.set_defaults(op=op_import_json)
subparser.add_argument('json_file', metavar='FILE', help='path to JSON file')
subparser.add_argument('--name', '-n', dest='name', metavar='NAME', help='symbolic name of the imported deployment')

subparser = add_subparser('info', help='show the state of the deployment')
subparser.set_defaults(op=op_info)
subparser.add_argument('--all',  action='store_true', help='show all deployments')
subparser.add_argument('--plain',  action='store_true', help='do not pretty-print the output')
subparser.add_argument('--no-eval', action='store_true', help='do not evaluate the deployment specification')

subparser = add_subparser('check', help='check the state of the machines in the network')
subparser.set_defaults(op=op_check)
subparser.add_argument('--all',  action='store_true', help='check all deployments')

subparser = add_subparser('set-args', help='persistently set arguments to the deployment specification')
subparser.set_defaults(op=op_set_args)
subparser.add_argument('--arg', nargs=2, action="append", dest="args", metavar=('NAME', 'VALUE'), help='pass a Nix expression value')
subparser.add_argument('--argstr', nargs=2, action="append", dest="argstrs", metavar=('NAME', 'VALUE'), help='pass a string value')
subparser.add_argument('--unset', nargs=1, action="append", dest="unset", metavar='NAME', help='unset previously set argument')

def add_common_deployment_options(subparser):
    subparser.add_argument('--include', nargs='+', metavar='MACHINE-NAME', help='perform deployment actions on the specified machines only')
    subparser.add_argument('--exclude', nargs='+', metavar='MACHINE-NAME', help='do not perform deployment actions on the specified machines')
    subparser.add_argument('--check', action='store_true', help='do not assume that the recorded state is correct')
    subparser.add_argument('--allow-reboot', action='store_true', help='reboot machines if necessary')
    subparser.add_argument('--max-concurrent-copy', type=int, default=5, metavar='N', help='maximum number of concurrent nix-copy-closure processes')

subparser = add_subparser('deploy', help='deploy the network configuration')
subparser.set_defaults(op=op_deploy)
subparser.add_argument('--kill-obsolete', '-k', action='store_true', help='kill obsolete virtual machines')
subparser.add_argument('--dry-run', action='store_true', help='show what would be done')
subparser.add_argument('--build-only', action='store_true', help='build only; do not perform deployment actions')
subparser.add_argument('--create-only', action='store_true', help='exit after creating missing machines')
subparser.add_argument('--copy-only', action='store_true', help='exit after copying closures')
add_common_deployment_options(subparser)

subparser = add_subparser('send-keys', help='send encryption keys')
subparser.set_defaults(op=op_send_keys)
subparser.add_argument('--include', nargs='+', metavar='MACHINE-NAME', help='send keys to only the specified machines')
subparser.add_argument('--exclude', nargs='+', metavar='MACHINE-NAME', help='send keys to all except the specified machines')

subparser = add_subparser('destroy', help='destroy all virtual machines in the network')
subparser.set_defaults(op=op_destroy)
subparser.add_argument('--include', nargs='+', metavar='MACHINE-NAME', help='destroy only the specified machines')
subparser.add_argument('--exclude', nargs='+', metavar='MACHINE-NAME', help='destroy all except the specified machines')

subparser = add_subparser('stop', help='stop all virtual machines in the network')
subparser.set_defaults(op=op_stop)
subparser.add_argument('--include', nargs='+', metavar='MACHINE-NAME', help='stop only the specified machines')
subparser.add_argument('--exclude', nargs='+', metavar='MACHINE-NAME', help='stop all except the specified machines')

subparser = add_subparser('start', help='start all virtual machines in the network')
subparser.set_defaults(op=op_start)
subparser.add_argument('--include', nargs='+', metavar='MACHINE-NAME', help='start only the specified machines')
subparser.add_argument('--exclude', nargs='+', metavar='MACHINE-NAME', help='start all except the specified machines')

subparser = add_subparser('reboot', help='reboot all virtual machines in the network')
subparser.set_defaults(op=op_reboot)
subparser.add_argument('--include', nargs='+', metavar='MACHINE-NAME', help='reboot only the specified machines')
subparser.add_argument('--exclude', nargs='+', metavar='MACHINE-NAME', help='reboot all except the specified machines')
subparser.add_argument('--wait', '-w', action='store_true', help='wait until the machines are up again')

subparser = add_subparser('show-physical', help='print the physical network expression')
subparser.set_defaults(op=op_show_physical)

subparser = add_subparser('ssh', help='login on the specified machine via SSH')
subparser.set_defaults(op=op_ssh)
subparser.add_argument('machine', metavar='MACHINE', help='identifier of the machine')
subparser.add_argument('args', metavar="ARG", nargs='*', help='additional arguments to SSH')

subparser = add_subparser('ssh-for-each', help='execute a command on each machine via SSH')
subparser.set_defaults(op=op_ssh_for_each)
subparser.add_argument('args', metavar="ARG", nargs='*', help='additional arguments to SSH')
subparser.add_argument('--parallel', '-p', action='store_true', help='run in parallel')

subparser = add_subparser('scp', help='copy files to or from the specified machine via scp')
subparser.set_defaults(op=op_scp)
subparser.add_argument('--from', dest='scp_from', action='store_true', help='copy a file from specified machine')
subparser.add_argument('--to', dest='scp_to', action='store_true', help='copy a file to specified machine')
subparser.add_argument('machine', metavar='MACHINE', help='identifier of the machine')
subparser.add_argument('source', metavar='SOURCE', help='source file location')
subparser.add_argument('destination', metavar='DEST', help='destination file location')

subparser = add_subparser('rename', help='rename machine in network')
subparser.set_defaults(op=op_rename)
subparser.add_argument('current_name', metavar='FROM', help='current identifier of the machine')
subparser.add_argument('new_name', metavar='TO', help='new identifier of the machine')

subparser = add_subparser('backup', help='make snapshots of persistent disks in network (currently EC2-only)')
subparser.set_defaults(op=op_backup)
subparser.add_argument('--include', nargs='+', metavar='MACHINE-NAME', help='perform backup actions on the specified machines only')
subparser.add_argument('--exclude', nargs='+', metavar='MACHINE-NAME', help='do not perform backup actions on the specified machines')
subparser.add_argument('--freeze', dest='freeze_fs', action="store_true", default=False, help='freeze filesystems for non-root filesystems that support this (e.g. xfs)')
subparser.add_argument('--force', dest='force', action="store_true", default=False, help='start new backup even if previous is still running')

subparser = add_subparser('backup-status', help='get status of backups')
subparser.set_defaults(op=op_backup_status)
subparser.add_argument('backupid', default=None, nargs='?', help='use specified backup in stead of latest')
subparser.add_argument('--include', nargs='+', metavar='MACHINE-NAME', help='perform backup actions on the specified machines only')
subparser.add_argument('--exclude', nargs='+', metavar='MACHINE-NAME', help='do not perform backup actions on the specified machines')
subparser.add_argument('--wait', dest='wait', action="store_true", default=False, help='wait until backup is finished')
subparser.add_argument('--latest', dest='latest', action="store_true", default=False, help='show status of latest backup only')

subparser = add_subparser('remove-backup', help='remove a given backup')
subparser.set_defaults(op=op_remove_backup)
subparser.add_argument('backupid', nargs='?', help='backup id to remove')

subparser = add_subparser('clean-backups', help='remove old backups')
subparser.set_defaults(op=op_clean_backups)
subparser.add_argument('--keep', dest="keep", type=int, default=10, help='number of backups to keep around')

subparser = add_subparser('restore', help='restore machines based on snapshots of persistent disks in network (currently EC2-only)')
subparser.set_defaults(op=op_restore)
subparser.add_argument('backupid', default=None, help='use specified backup in stead of latest')
subparser.add_argument('--include', nargs='+', metavar='MACHINE-NAME', help='perform backup actions on the specified machines only')
subparser.add_argument('--exclude', nargs='+', metavar='MACHINE-NAME', help='do not perform backup actions on the specified machines')

subparser = add_subparser('show-option', help='print the value of a configuration option')
subparser.set_defaults(op=op_show_option)
subparser.add_argument('machine', metavar='MACHINE', help='identifier of the machine')
subparser.add_argument('option', metavar='OPTION', help='option name')
subparser.add_argument('--xml', action='store_true', help='print the option value in XML format')

subparser = add_subparser('list-generations', help='list previous configurations to which you can roll back')
subparser.set_defaults(op=op_list_generations)

subparser = add_subparser('rollback', help='roll back to a previous configuration')
subparser.set_defaults(op=op_rollback)
subparser.add_argument('generation', type=int, metavar='GENERATION', help='number of the desired configuration (see ‘charon list-generations’)')
add_common_deployment_options(subparser)


# Parse the command line and execute the desired operation.
args = parser.parse_args()
try:
    charon.deployment.debug = args.debug
    args.op()
except deployment.NixEvalError:
    print >> sys.stderr, "error: evaluation of the deployment specification failed"
    sys.exit(1)
except KeyboardInterrupt:
    print >> sys.stderr, "error: interrupted"
    sys.exit(1)
except Exception as e:
    if args.debug or str(e) == "": raise
    print >> sys.stderr, "error:", str(e)
    sys.exit(1)
